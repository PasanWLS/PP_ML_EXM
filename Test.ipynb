{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fix the Code (Marks 30)\n",
    "<pre>\n",
    " - Read the given paper carefully.\n",
    " - Separate the code into multiple cells and explain the code and each segment in Markdown. \n",
    " - Rename and change the variable name for meaningful names.\n",
    " - Clean and remove the commented codes and print codes.\n",
    " - Get the final test accuracy and loss and print it.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, models, optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPooling2D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = \"G:\\\\ML_Exam\\\\ml-2023-test\\\\concrete\\\\\"      # image folder directory\n",
    "m =  \"G:\\\\ML_Exam\\\\ml-2023-test\\\\trainedModel\\\\\" # \n",
    "img_size = 64                                    # resizing to image size\n",
    "nb_epochs = 10                                   # no of epochs to train the model\n",
    "validation_split = 0.2                           # 20% of images from both folders are taken for validation\n",
    "                                                 # other 80% are taken for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading and normalizing and seperating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32000 images belonging to 2 classes.\n",
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   validation_split=validation_split)  # normalize the images and set validation split\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    d,\n",
    "    target_size=(img_size, img_size),\n",
    "    class_mode= 'binary', # only two classes are there: binary\n",
    "    subset='training')    # set as training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    d,\n",
    "    target_size=(img_size, img_size),\n",
    "    class_mode='binary', \n",
    "    subset='validation')  # set as validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model. \n",
    "#### Since we are dealing with unstructured data (images), we will use a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "#convolutional layer and maxpool layer 1\n",
    "model.add(Conv2D(32,(3,3),1, input_shape=(img_size,img_size,3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "#convolutional layer and maxpool layer 2\n",
    "model.add(Conv2D(32,(3,3),1, activation = 'relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "#flattens the resulting image array to 1D array\n",
    "model.add(Flatten())\n",
    "\n",
    "#Hidden layer with 32 neurones and Rectified Linear Unit activation function\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "#Output layer with single neurone, which will give 0 for Negative and 1 for Positive\n",
    "#Sigmoid activation function will make sure our output lies between 0-1\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the created model using following\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 800)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                25632     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35809 (139.88 KB)\n",
      "Trainable params: 35809 (139.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the callback to save the best model based depending on validation accuracy\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=m,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,     # Save only the best model\n",
    "    mode='max',              # maximize the chosen metric\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mg:\\ML_Exam\\ml-2023-test\\Test.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML_Exam/ml-2023-test/Test.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Training the model with training data and validation data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/ML_Exam/ml-2023-test/Test.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator, validation_data\u001b[39m=\u001b[39;49mvalidation_generator, callbacks\u001b[39m=\u001b[39;49m[\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML_Exam/ml-2023-test/Test.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     checkpoint_callback], epochs\u001b[39m=\u001b[39;49mnb_epochs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML_Exam/ml-2023-test/Test.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m##ImportError: Could not import PIL.Image. The use of `load_img` requires PIL.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\EES\\miniconda3\\envs\\ml-2023\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\EES\\miniconda3\\envs\\ml-2023\\lib\\site-packages\\keras\\src\\utils\\image_utils.py:414\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    412\u001b[0m     color_mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgrayscale\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m \u001b[39mif\u001b[39;00m pil_image \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import PIL.Image. The use of `load_img` requires PIL.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m     )\n\u001b[0;32m    417\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, io\u001b[39m.\u001b[39mBytesIO):\n\u001b[0;32m    418\u001b[0m     img \u001b[39m=\u001b[39m pil_image\u001b[39m.\u001b[39mopen(path)\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "#Training the model with training data and validation data\n",
    "\n",
    "history = model.fit(train_generator, validation_data=validation_generator, callbacks=[\n",
    "                    checkpoint_callback], epochs=nb_epochs)\n",
    "\n",
    "##ImportError: Could not import PIL.Image. The use of `load_img` requires PIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mg:\\ML_Exam\\ml-2023-test\\Test.ipynb Cell 13\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML_Exam/ml-2023-test/Test.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#plotting the accuracy and validation accuracy\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML_Exam/ml-2023-test/Test.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#can detect underfitting and any overfitting\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/ML_Exam/ml-2023-test/Test.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mteal\u001b[39m\u001b[39m'\u001b[39m ,label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML_Exam/ml-2023-test/Test.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m], color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mred\u001b[39m\u001b[39m'\u001b[39m ,label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/ML_Exam/ml-2023-test/Test.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#accuracy plotted against no of epochs \u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "#plotting the accuracy and validation accuracy\n",
    "#can detect underfitting and any overfitting\n",
    "\n",
    "plt.plot(history.history['accuracy'], color='teal' ,label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], color='red' ,label = 'val_accuracy')\n",
    "\n",
    "#accuracy plotted against no of epochs \n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "#output is plotted inbetween 0-100%\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Continuing with the example best.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "\n",
    "model = tf.keras.models.load_model(\"G:\\\\ML_Exam\\\\ml-2023-test\\\\example\\\\best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Negative': 0, 'Positive': 1}\n"
     ]
    }
   ],
   "source": [
    "labels = (train_generator.class_indices)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing with test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './test/' #path to the test images\n",
    "k = [] #array of images\n",
    "names = [] #array of image names\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    p = os.path.join(path, filename)\n",
    "    if 'jpg' in p:\n",
    "        # print(p)\n",
    "        c = cv2.imread(p) #read the image \n",
    "        c = cv2.resize(c, (img_size, img_size), interpolation=cv2.INTER_LINEAR) #resize the read image\n",
    "        k.append(c) \n",
    "        names.append(filename)\n",
    "k = np.array(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 64, 64, 3)\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(k.shape)\n",
    "print(np.size(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names =  [0,1] #class names of two categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "(12, 1)\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "#storing the fact if predicted value is greater/less than 0.5\n",
    "#which category the k values belong to\n",
    "\n",
    "predicted_labels = (model.predict(k) > 0.5).astype(\"int32\") \n",
    "print(predicted_labels.shape)\n",
    "print(predicted_labels) #2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n",
      "[0 0 0 0 0 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = predicted_labels.flatten()\n",
    "print(predicted_labels.shape)\n",
    "print(predicted_labels) # 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = [class_names[i] for i in predicted_labels]\n",
    "print(predicted_labels) #list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n00001.jpg', 'n00002.jpg', 'n00003.jpg', 'n00004.jpg', 'n00005.jpg', 'n00006.jpg', 'p00001.jpg', 'p00002.jpg', 'p00003.jpg', 'p00004.jpg', 'p00005.jpg', 'p00006.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the results of the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = []\n",
    "for i in names:\n",
    "\n",
    "    #if image contains 'n', which is negatives, 0 added to test_arr\n",
    "    if i[0] == 'n': \n",
    "        test_arr.append(0) \n",
    "\n",
    "    #if image contains 'p', which is negatives, 1 added to test_arr    \n",
    "    elif i[0] == 'p' : \n",
    "        test_arr.append(1)\n",
    "\n",
    "test_arr = np.array(test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the accuracy and loss of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 779ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "if (len(test_arr) == len(k)):\n",
    "    score = model.evaluate(k, test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "{'Negative': 0, 'Positive': 1}\n",
      "['n00001.jpg', 'n00002.jpg', 'n00003.jpg', 'n00004.jpg', 'n00005.jpg', 'n00006.jpg', 'p00001.jpg', 'p00002.jpg', 'p00003.jpg', 'p00004.jpg', 'p00005.jpg', 'p00006.jpg']\n",
      "Test loss: 0.0\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "if (len(test_arr) == len(k)):\n",
    "    \n",
    "    score = model.evaluate(k, test_arr)\n",
    "\n",
    "    print(labels)\n",
    "    print(names)\n",
    "\n",
    "    print('Test loss:', score[0]) \n",
    "    print('Test accuracy:', score[1]) \n",
    "    \n",
    "else:\n",
    "    print(\"Something wrong with the prediction.\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
